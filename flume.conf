# flume-logger-hdfs.conf: Read data from logs and write it to both logger and hdfs

# Name the components on this agent
raouf.sources = logsource
raouf.sinks = loggersink hdfssink
raouf.channels = loggerchannel hdfschannel

# Describe/configure the source
raouf.sources.logsource.type = exec
raouf.sources.logsource.command = tail -F /opt/gen_logs/logs/access.log

# Describe the sink
raouf.sinks.loggersink.type = logger

# Use a channel which buffers events in memory
raouf.channels.loggerchannel.type = memory
raouf.channels.loggerchannel.capacity = 1000
raouf.channels.loggerchannel.transactionCapacity = 100

# Bind the source and sink to the channel
raouf.sources.logsource.channels = loggerchannel hdfschannel
raouf.sinks.loggersink.channel = loggerchannel

#Describe the sink
raouf.sinks.hdfssink.type = hdfs
raouf.sinks.hdfssink.hdfs.path = hdfs://nn01.itversity.com:8020/user/raoufkhan/flume_example_%Y-%m-%d
raouf.sinks.hdfssink.hdfs.fileType = DataStream
raouf.sinks.hdfssink.hdfs.rollInterval = 120
raouf.sinks.hdfssink.hdfs.rollSize = 10485760
raouf.sinks.hdfssink.hdfs.rollCount = 30
raouf.sinks.hdfssink.hdfs.filePrefix = retail
raouf.sinks.hdfssink.hdfs.fileSuffix = .txt
raouf.sinks.hdfssink.hdfs.inUseSuffix = .tmp
raouf.sinks.hdfssink.hdfs.useLocalTimeStamp = true

#Use a channel which buffers events in file for HDFS sink
raouf.channels.hdfschannel.type = file
raouf.channels.hdfschannel.capacity = 1000
raouf.channels.hdfschannel.transactionCapacity = 100
raouf.channels.hdfschannel.checkpointInterval = 300

raouf.sinks.hdfssink.channel = hdfschannel